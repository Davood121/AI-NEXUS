import subprocess
import json
import os

def check_ai_hardware():
    """Check if AI is running on CPU or GPU"""
    print("ğŸ” Checking AI Hardware Configuration...")
    print("="*50)
    
    # Check Ollama status
    try:
        result = subprocess.run(['ollama', 'ps'], capture_output=True, text=True)
        if result.returncode == 0:
            print("ğŸ“Š Ollama Models Status:")
            print(result.stdout)
        else:
            print("âŒ Ollama not running")
    except:
        print("âŒ Ollama not found")
    
    # Check GPU availability
    try:
        import torch
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            gpu_name = torch.cuda.get_device_name(0)
            print(f"ğŸ® GPU Available: {gpu_name}")
            print(f"ğŸ”¢ GPU Count: {gpu_count}")
            print(f"ğŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        else:
            print("ğŸ’» Running on CPU only")
    except ImportError:
        print("ğŸ’» PyTorch not installed - likely CPU only")
    
    # Check system info
    try:
        import psutil
        cpu_count = psutil.cpu_count()
        memory = psutil.virtual_memory()
        print(f"ğŸ–¥ï¸ CPU Cores: {cpu_count}")
        print(f"ğŸ’¾ RAM: {memory.total / 1024**3:.1f} GB")
        print(f"ğŸ“ˆ RAM Usage: {memory.percent}%")
    except ImportError:
        print("ğŸ“Š System info not available")
    
    # Check Ollama configuration
    try:
        # Check if CUDA is being used by Ollama
        result = subprocess.run(['ollama', 'show', 'phi3:mini'], capture_output=True, text=True)
        if 'cuda' in result.stdout.lower() or 'gpu' in result.stdout.lower():
            print("ğŸš€ Ollama using GPU acceleration")
        else:
            print("ğŸŒ Ollama using CPU")
    except:
        pass
    
    print("\n" + "="*50)
    print("ğŸ’¡ Performance Tips:")
    print("- GPU: 1-3 seconds response time")
    print("- CPU: 5-15 seconds response time")
    print("- For GPU: Install CUDA drivers")
    print("- For better CPU: Use phi3:mini model")

if __name__ == "__main__":
    check_ai_hardware()